{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User feature columns: ['user_avg_rating', 'user_rating_count', 'user_rating_std', 'user_rating_max', 'user_rating_min', 'user_last_timestamp', 'Action', 'Adventure', 'Animation', 'Children', 'Comedy', 'Crime', 'Documentary', 'Drama', 'Fantasy', 'Film-Noir', 'Horror', 'IMAX', 'Musical', 'Mystery', 'Romance', 'Sci-Fi', 'Thriller', 'War', 'Western']\n",
      "Movie feature columns: ['(no genres listed)', 'Action', 'Adventure', 'Animation', 'Children', 'Comedy', 'Crime', 'Documentary', 'Drama', 'Fantasy', 'Film-Noir', 'Horror', 'IMAX', 'Musical', 'Mystery', 'Romance', 'Sci-Fi', 'Thriller', 'War', 'Western', 'movie_avg_rating', 'movie_rating_count', 'movie_rating_std']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# ================================\n",
    "# 1. 读取并准备数据\n",
    "# ================================\n",
    "user_features = pd.read_csv('user_features.csv')\n",
    "movie_features = pd.read_csv('movie_features.csv')\n",
    "ratings = pd.read_csv('ratings_cleaned.csv')  # 包含 userId, movieId, rating, ts(或timestamp)\n",
    "\n",
    "# 建立 userId 和 movieId 到连续索引的映射\n",
    "unique_users = user_features['userId'].unique()\n",
    "unique_movies = movie_features['movieId'].unique()\n",
    "\n",
    "user2index = {u: i for i, u in enumerate(unique_users)}\n",
    "movie2index = {m: i for i, m in enumerate(unique_movies)}\n",
    "\n",
    "# 在 user_features 和 movie_features 中新增一列 idx\n",
    "user_features['user_idx'] = user_features['userId'].map(user2index)\n",
    "movie_features['movie_idx'] = movie_features['movieId'].map(movie2index)\n",
    "\n",
    "# 筛选我们需要的特征列（示例中直接保留除去 userId, user_idx 以外的列都当作特征）\n",
    "# 你也可以根据需求手动指定特征列\n",
    "user_feature_cols = [c for c in user_features.columns if c not in ['userId','user_idx']]\n",
    "movie_feature_cols = [c for c in movie_features.columns if c not in ['movieId','movie_idx','title','genres','year']]\n",
    "\n",
    "print(\"User feature columns:\", user_feature_cols)\n",
    "print(\"Movie feature columns:\", movie_feature_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# ================================\n",
    "# 2. 多通道召回函数\n",
    "# ================================\n",
    "# 2.1 基于规则的召回\n",
    "# -------------------------------\n",
    "# 示例：热门召回 (movie_rating_count 排序) / 高分召回 (movie_avg_rating 排序)\n",
    "def rule_based_recall(top_k=50, method='popularity'):\n",
    "    if method == 'popularity':\n",
    "        sorted_df = movie_features.sort_values('movie_rating_count', ascending=False)\n",
    "    elif method == 'high_score':\n",
    "        sorted_df = movie_features.sort_values('movie_avg_rating', ascending=False)\n",
    "    else:\n",
    "        sorted_df = movie_features.sort_values('movie_rating_count', ascending=False)\n",
    "    return sorted_df.head(top_k)['movieId'].tolist()\n",
    "\n",
    "# 2.2 基于协同过滤（Item-based CF）召回\n",
    "# -------------------------------\n",
    "# 构建物品相似度矩阵（余弦相似度）\n",
    "ratings_pivot = ratings.pivot_table(index='userId', columns='movieId', values='rating', fill_value=0)\n",
    "item_user_matrix = ratings_pivot.T  # 行=movieId, 列=userId\n",
    "# 计算余弦相似度\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "similarity_matrix = cosine_similarity(item_user_matrix.values)\n",
    "similarity_df = pd.DataFrame(similarity_matrix, \n",
    "                             index=item_user_matrix.index, \n",
    "                             columns=item_user_matrix.index)\n",
    "\n",
    "def cf_recall(user_id, top_n=50, rating_threshold=3.5):\n",
    "    if user_id not in ratings_pivot.index:\n",
    "        # 如果该用户在训练集中不存在，则用热门召回\n",
    "        return rule_based_recall(top_k=top_n)\n",
    "    user_ratings = ratings_pivot.loc[user_id]\n",
    "    liked_movies = user_ratings[user_ratings >= rating_threshold].index\n",
    "    \n",
    "    score_series = pd.Series(dtype=float)\n",
    "    for mid in liked_movies:\n",
    "        score_series = score_series.add(similarity_df[mid], fill_value=0)\n",
    "    \n",
    "    # 去掉用户看过的电影\n",
    "    score_series = score_series.drop(liked_movies, errors='ignore')\n",
    "    score_series = score_series.sort_values(ascending=False)\n",
    "    return score_series.head(top_n).index.tolist()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Loss: 0.6844\n",
      "Epoch 2/5, Loss: 0.6672\n",
      "Epoch 3/5, Loss: 0.6621\n",
      "Epoch 4/5, Loss: 0.6546\n",
      "Epoch 5/5, Loss: 0.6527\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ================================\n",
    "# 3. 双塔模型 (PyTorch)\n",
    "# ================================\n",
    "# 3.1 定义SENet模块\n",
    "class SENetLayer(nn.Module):\n",
    "    \"\"\"\n",
    "    PyTorch 版 SENet (简化): Squeeze and Excitation\n",
    "    \"\"\"\n",
    "    def __init__(self, channel_dim, reduction_ratio=4):\n",
    "        super(SENetLayer, self).__init__()\n",
    "        hidden_dim = channel_dim // reduction_ratio\n",
    "        self.fc_squeeze = nn.Linear(channel_dim, hidden_dim)\n",
    "        self.fc_excitation = nn.Linear(hidden_dim, channel_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: [batch_size, channel_dim]\n",
    "        \"\"\"\n",
    "        # Squeeze: Global Average Pooling (对batch内每个样本自身的feature做平均)\n",
    "        # 但这里 x 已经是 [batch, channel_dim]，相当于 seq_len=1 情况\n",
    "        # 也可以对多维度做 pooling，这里做简化\n",
    "        avg = x.mean(dim=0, keepdim=True)  # 也可以 mean(dim=1) 看具体需求\n",
    "        # 如果要做真正的通道注意力，需要在CNN或多时序维度的场景更明显\n",
    "        # 这里只是模拟流程\n",
    "        \n",
    "        # 全连接\n",
    "        z = self.fc_squeeze(avg)      # [1, hidden_dim]\n",
    "        z = self.relu(z)\n",
    "        z = self.fc_excitation(z)     # [1, channel_dim]\n",
    "        z = self.sigmoid(z)           # [1, channel_dim]\n",
    "        \n",
    "        # 通道注意力乘法\n",
    "        # broadcast到 [batch_size, channel_dim]\n",
    "        scale = x * z\n",
    "        return scale\n",
    "\n",
    "# 3.2 定义User Tower和Item Tower\n",
    "class UserTower(nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim=16):\n",
    "        super(UserTower, self).__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(input_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            # SENet\n",
    "            # 由于 PyTorch MLP 直接是 [batch, feature_dim], 我们这里用一个SENet对这维度做处理\n",
    "            SENetLayer(channel_dim=64, reduction_ratio=4),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, emb_dim)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: [batch_size, input_dim]\n",
    "        return: [batch_size, emb_dim]\n",
    "        \"\"\"\n",
    "        out = self.mlp(x)  # [batch_size, emb_dim]\n",
    "        # L2 normalize\n",
    "        out = nn.functional.normalize(out, p=2, dim=1)\n",
    "        return out\n",
    "\n",
    "class ItemTower(nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim=16):\n",
    "        super(ItemTower, self).__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(input_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            SENetLayer(channel_dim=64, reduction_ratio=4),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, emb_dim)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.mlp(x)\n",
    "        out = nn.functional.normalize(out, p=2, dim=1)\n",
    "        return out\n",
    "\n",
    "# 3.3 定义双塔模型\n",
    "class TwoTowerModel(nn.Module):\n",
    "    def __init__(self, user_dim, item_dim, emb_dim=16):\n",
    "        super(TwoTowerModel, self).__init__()\n",
    "        self.user_tower = UserTower(user_dim, emb_dim=emb_dim)\n",
    "        self.item_tower = ItemTower(item_dim, emb_dim=emb_dim)\n",
    "    \n",
    "    def forward(self, user_x, item_x):\n",
    "        \"\"\"\n",
    "        user_x: [batch_size, user_dim]\n",
    "        item_x: [batch_size, item_dim]\n",
    "        return: [batch_size, 1] (sigmoid后的点击/喜好概率)\n",
    "        \"\"\"\n",
    "        u_emb = self.user_tower(user_x)  # [batch, emb_dim]\n",
    "        i_emb = self.item_tower(item_x)  # [batch, emb_dim]\n",
    "        \n",
    "        # dot => 余弦相似度 (因已做 L2 norm)\n",
    "        logit = torch.sum(u_emb * i_emb, dim=1, keepdim=True)  # [batch,1]\n",
    "        out = torch.sigmoid(logit)  # (0,1)\n",
    "        return out\n",
    "\n",
    "# 3.4 构建训练数据\n",
    "# -------------------------------\n",
    "# 示例: 将评分 >= 3.5 视为正样本, 否则负样本\n",
    "ratings['label'] = (ratings['rating'] >= 3.5).astype(int)\n",
    "# 采样一部分数据用于演示\n",
    "ratings_sample = ratings.sample(frac=0.01, random_state=42)\n",
    "\n",
    "# 准备 user_feature, item_feature\n",
    "def get_user_feature(u_id):\n",
    "    u_idx = user2index[u_id]\n",
    "    row = user_features.loc[user_features['user_idx'] == u_idx, user_feature_cols]\n",
    "    return row.values[0]\n",
    "\n",
    "def get_item_feature(i_id):\n",
    "    i_idx = movie2index[i_id]\n",
    "    row = movie_features.loc[movie_features['movie_idx'] == i_idx, movie_feature_cols]\n",
    "    return row.values[0]\n",
    "\n",
    "class TwoTowerDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        super(TwoTowerDataset, self).__init__()\n",
    "        self.samples = df[['userId','movieId','label']].values\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        user_id, movie_id, label = self.samples[idx]\n",
    "        user_feat = get_user_feature(user_id)\n",
    "        item_feat = get_item_feature(movie_id)\n",
    "        return torch.tensor(user_feat, dtype=torch.float32), \\\n",
    "               torch.tensor(item_feat, dtype=torch.float32), \\\n",
    "               torch.tensor(label, dtype=torch.float32)\n",
    "\n",
    "dataset = TwoTowerDataset(ratings_sample)\n",
    "dataloader = DataLoader(dataset, batch_size=256, shuffle=True)\n",
    "\n",
    "# 3.5 训练模型\n",
    "user_dim = len(user_feature_cols)\n",
    "item_dim = len(movie_feature_cols)\n",
    "emb_dim = 16\n",
    "\n",
    "model = TwoTowerModel(user_dim, item_dim, emb_dim=emb_dim)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# 这里简单地跑几轮\n",
    "epochs = 5\n",
    "model.train()\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0.0\n",
    "    for user_x, item_x, label in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(user_x, item_x)\n",
    "        loss = criterion(pred, label.unsqueeze(1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss/len(dataloader):.4f}\")\n",
    "\n",
    "# 3.6 生成全量 embedding\n",
    "# -------------------------------\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # 计算所有电影embedding\n",
    "    all_item_idx = movie_features['movie_idx'].values\n",
    "    item_feat_mat = movie_features[movie_feature_cols].values\n",
    "    item_feat_tensor = torch.tensor(item_feat_mat, dtype=torch.float32)\n",
    "    all_item_emb = model.item_tower(item_feat_tensor)  # [num_items, emb_dim]\n",
    "    \n",
    "    # 建立 idx2movie\n",
    "    idx2movie = {v: k for k, v in movie2index.items()}\n",
    "\n",
    "def tower_recall(user_id, top_n=50):\n",
    "    \"\"\"\n",
    "    使用训练好的双塔模型做召回\n",
    "    1. 计算该用户embedding\n",
    "    2. 与所有item embedding做相似度(点积)\n",
    "    3. 取 top_n\n",
    "    \"\"\"\n",
    "    if user_id not in user2index:\n",
    "        return rule_based_recall(top_k=top_n)\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # 获取用户特征\n",
    "        u_feat = get_user_feature(user_id)\n",
    "        u_feat_tensor = torch.tensor(u_feat, dtype=torch.float32).unsqueeze(0)  # [1, user_dim]\n",
    "        user_emb = model.user_tower(u_feat_tensor)  # [1, emb_dim]\n",
    "        \n",
    "        # 计算相似度\n",
    "        # 因为已 L2 normalize, dot 即 cosine\n",
    "        sim = torch.matmul(all_item_emb, user_emb.squeeze(0))  # [num_items]\n",
    "        sim = sim.numpy()  # 转成 numpy\n",
    "        \n",
    "        # 排序\n",
    "        top_indices = np.argsort(sim)[::-1][:top_n]\n",
    "        top_movie_ids = [idx2movie[all_item_idx[i]] for i in top_indices]\n",
    "        return top_movie_ids\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ================================\n",
    "# 4. 多通道召回控制\n",
    "# ================================\n",
    "def multi_channel_recall(user_id, top_n=50, channels=['rule','cf','tower']):\n",
    "    candidates = set()\n",
    "    for ch in channels:\n",
    "        if ch == 'rule':\n",
    "            # 默认热门召回\n",
    "            c = rule_based_recall(top_k=top_n, method='popularity')\n",
    "            candidates.update(c)\n",
    "        elif ch == 'cf':\n",
    "            c = cf_recall(user_id, top_n=top_n)\n",
    "            candidates.update(c)\n",
    "        elif ch == 'tower':\n",
    "            c = tower_recall(user_id, top_n=top_n)\n",
    "            candidates.update(c)\n",
    "        else:\n",
    "            pass\n",
    "    # 简单去重后截取\n",
    "    candidates_list = list(candidates)\n",
    "    if len(candidates_list) > top_n:\n",
    "        candidates_list = candidates_list[:top_n]\n",
    "    return candidates_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "测试用户ID: 275\n",
      "规则通道召回: [480, 356, 260, 296, 2571, 589, 110, 527, 593, 318]\n",
      "CF通道召回: [4384, 5884, 1574, 1641, 5258, 298, 2964, 1206, 5272, 3192]\n",
      "双塔通道召回: [4384, 4386, 4387, 4388, 4389, 4390, 4392, 193609, 4394, 4393]\n",
      "全部通道召回: [260, 5258, 2571, 527, 2964, 5272, 4384, 4386, 4387, 4388]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ================================\n",
    "# 5. 测试\n",
    "# ================================\n",
    "test_user_id = user_features['userId'].sample(1).iloc[0]\n",
    "print(\"测试用户ID:\", test_user_id)\n",
    "\n",
    "rule_candidates = multi_channel_recall(test_user_id, top_n=10, channels=['rule'])\n",
    "print(\"规则通道召回:\", rule_candidates)\n",
    "\n",
    "cf_candidates = multi_channel_recall(test_user_id, top_n=10, channels=['cf'])\n",
    "print(\"CF通道召回:\", cf_candidates)\n",
    "\n",
    "tower_candidates = multi_channel_recall(test_user_id, top_n=10, channels=['tower'])\n",
    "print(\"双塔通道召回:\", tower_candidates)\n",
    "\n",
    "all_candidates = multi_channel_recall(test_user_id, top_n=10, channels=['rule','cf','tower'])\n",
    "print(\"全部通道召回:\", all_candidates)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
