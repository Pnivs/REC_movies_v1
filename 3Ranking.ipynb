{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import math\n",
    "\n",
    "#########################################\n",
    "# 1. 数据准备与异常值处理\n",
    "#########################################\n",
    "\n",
    "# 读取 CSV 数据（请确保文件路径正确）\n",
    "user_df = pd.read_csv('user_features.csv')\n",
    "item_df = pd.read_csv('movie_features.csv')\n",
    "ratings_df = pd.read_csv('ratings_cleaned.csv')\n",
    "\n",
    "# 对数据中的 NaN、无穷大做处理（例如填充0）\n",
    "user_df = user_df.replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "item_df = item_df.replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "ratings_df = ratings_df.replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "\n",
    "# 建立 userId, movieId 映射（如果文件中没有 user_idx/item_idx 则生成）\n",
    "user_ids = user_df['userId'].unique()\n",
    "item_ids = item_df['movieId'].unique()\n",
    "user2index = {u: i for i, u in enumerate(user_ids)}\n",
    "item2index = {m: i for i, m in enumerate(item_ids)}\n",
    "\n",
    "if 'user_idx' not in user_df.columns:\n",
    "    user_df['user_idx'] = user_df['userId'].map(user2index)\n",
    "if 'item_idx' not in item_df.columns:\n",
    "    item_df['item_idx'] = item_df['movieId'].map(item2index)\n",
    "\n",
    "# 除去标识列，其余全部视为数值特征（请确保这些列为数值型）\n",
    "user_feature_cols = [col for col in user_df.columns if col not in ['userId','user_idx']]\n",
    "item_feature_cols = [col for col in item_df.columns if col not in ['movieId','item_idx','title','genres','year']]\n",
    "\n",
    "# 将评分二值化：rating>=3.5 -> 1, 否则 0\n",
    "ratings_df['label'] = (ratings_df['rating'] >= 3.5).astype(int)\n",
    "ratings_df['label'] = ratings_df['label'].clip(0,1)  # 再次确保标签在 [0,1]\n",
    "\n",
    "# 构造正样本数据\n",
    "pos_df = ratings_df[ratings_df['label'] == 1].copy()\n",
    "\n",
    "# 对每个用户采样5个负样本（未发生交互）\n",
    "neg_samples = []\n",
    "all_item_set = set(item_ids)\n",
    "for u in ratings_df['userId'].unique():\n",
    "    pos_items = set(pos_df[pos_df['userId'] == u]['movieId'].unique())\n",
    "    neg_candidates = list(all_item_set - pos_items)\n",
    "    if len(neg_candidates) >= 5:\n",
    "        neg_items = np.random.choice(neg_candidates, size=5, replace=False)\n",
    "    else:\n",
    "        neg_items = neg_candidates\n",
    "    for i in neg_items:\n",
    "        neg_samples.append((u, i, 0))\n",
    "neg_df = pd.DataFrame(neg_samples, columns=['userId','movieId','label'])\n",
    "\n",
    "# 合并正负样本并打乱\n",
    "data_df = pd.concat([pos_df[['userId','movieId','label']], neg_df], ignore_index=True)\n",
    "data_df = data_df.sample(frac=1.0, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# 划分训练、验证、测试集\n",
    "train_df, test_df = train_test_split(data_df, test_size=0.2, random_state=42)\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Train size:\", len(train_df))\n",
    "print(\"Val size:\", len(val_df))\n",
    "print(\"Test size:\", len(test_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#########################################\n",
    "# 2. Dataset 定义（含 DIN 历史行为）\n",
    "#########################################\n",
    "\n",
    "# 为 DIN 模型构造用户历史正样本字典：userId -> list of item-feature vectors\n",
    "user_history = {}\n",
    "for u in pos_df['userId'].unique():\n",
    "    items = pos_df[pos_df['userId'] == u]['movieId'].tolist()\n",
    "    feats = []\n",
    "    for item in items:\n",
    "        row = item_df[item_df['movieId'] == item][item_feature_cols].values\n",
    "        if len(row) > 0:\n",
    "            feats.append(row[0])\n",
    "    user_history[u] = feats\n",
    "\n",
    "# 基础数据集：返回 (user_feat, item_feat, label)\n",
    "class RankingDataset(Dataset):\n",
    "    def __init__(self, df, model_type='base', max_hist=5):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.model_type = model_type\n",
    "        self.max_hist = max_hist\n",
    "        self.user_history = user_history if model_type=='din' else None\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        u_id = row['userId']\n",
    "        i_id = row['movieId']\n",
    "        label = row['label']\n",
    "        # 从 user_df、item_df 中获取特征时，也进行异常值处理\n",
    "        u_feat = user_df[user_df['userId'] == u_id][user_feature_cols].values[0]\n",
    "        i_feat = item_df[item_df['movieId'] == i_id][item_feature_cols].values[0]\n",
    "        # 如果 DIN，需要用户历史行为；不足则 padding 0 向量\n",
    "        if self.model_type == 'din':\n",
    "            hist = self.user_history.get(u_id, [])\n",
    "            if len(hist) > self.max_hist:\n",
    "                hist = hist[-self.max_hist:]\n",
    "            else:\n",
    "                while len(hist) < self.max_hist:\n",
    "                    hist.append(np.zeros_like(i_feat))\n",
    "            hist = np.array(hist)  # [max_hist, item_dim]\n",
    "            return (torch.tensor(u_feat, dtype=torch.float32),\n",
    "                    torch.tensor(i_feat, dtype=torch.float32),\n",
    "                    torch.tensor(hist, dtype=torch.float32),\n",
    "                    torch.tensor(label, dtype=torch.float32).clamp(0,1))\n",
    "        else:\n",
    "            return (torch.tensor(u_feat, dtype=torch.float32),\n",
    "                    torch.tensor(i_feat, dtype=torch.float32),\n",
    "                    torch.tensor(label, dtype=torch.float32).clamp(0,1))\n",
    "\n",
    "train_dataset_base = RankingDataset(train_df, model_type='base')\n",
    "val_dataset_base = RankingDataset(val_df, model_type='base')\n",
    "test_dataset_base = RankingDataset(test_df, model_type='base')\n",
    "\n",
    "train_dataset_din = RankingDataset(train_df, model_type='din')\n",
    "val_dataset_din = RankingDataset(val_df, model_type='din')\n",
    "test_dataset_din = RankingDataset(test_df, model_type='din')\n",
    "\n",
    "batch_size = 256\n",
    "train_loader_base = DataLoader(train_dataset_base, batch_size=batch_size, shuffle=True)\n",
    "val_loader_base = DataLoader(val_dataset_base, batch_size=batch_size, shuffle=False)\n",
    "test_loader_base = DataLoader(test_dataset_base, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "train_loader_din = DataLoader(train_dataset_din, batch_size=batch_size, shuffle=True)\n",
    "val_loader_din = DataLoader(val_dataset_din, batch_size=batch_size, shuffle=False)\n",
    "test_loader_din = DataLoader(test_dataset_din, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "user_dim = len(user_feature_cols)\n",
    "item_dim = len(item_feature_cols)\n",
    "input_dim = user_dim + item_dim  # 用于 DCN、DeepFM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#########################################\n",
    "# 3. 模型定义（确保输出在 (1e-7, 1-1e-7)）\n",
    "#########################################\n",
    "\n",
    "# 3.1 DCN 模型\n",
    "class CrossLayer(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(CrossLayer, self).__init__()\n",
    "        self.weight = nn.Parameter(torch.randn(input_dim))\n",
    "        self.bias = nn.Parameter(torch.randn(input_dim))\n",
    "    \n",
    "    def forward(self, x0, xl):\n",
    "        xw = torch.sum(xl * self.weight, dim=1, keepdim=True)\n",
    "        out = x0 * xw + self.bias + xl\n",
    "        return out\n",
    "\n",
    "class DCN(nn.Module):\n",
    "    def __init__(self, input_dim, num_cross=2, deep_hidden=[64,32]):\n",
    "        super(DCN, self).__init__()\n",
    "        self.cross_layers = nn.ModuleList([CrossLayer(input_dim) for _ in range(num_cross)])\n",
    "        deep_layers = []\n",
    "        in_dim = input_dim\n",
    "        for hu in deep_hidden:\n",
    "            deep_layers.append(nn.Linear(in_dim, hu))\n",
    "            deep_layers.append(nn.ReLU())\n",
    "            in_dim = hu\n",
    "        self.deep = nn.Sequential(*deep_layers)\n",
    "        self.fc = nn.Linear(input_dim + deep_hidden[-1], 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x0 = x\n",
    "        xl = x\n",
    "        for layer in self.cross_layers:\n",
    "            xl = layer(x0, xl)\n",
    "        deep_out = self.deep(x0)\n",
    "        concat = torch.cat([xl, deep_out], dim=1)\n",
    "        logit = self.fc(concat)\n",
    "        # 保证输出在 (1e-7, 1-1e-7)\n",
    "        return torch.clamp(torch.sigmoid(logit), 1e-7, 1-1e-7).squeeze(-1)\n",
    "\n",
    "# 3.2 DIN 模型（简化版）\n",
    "class AttentionUnit(nn.Module):\n",
    "    def __init__(self, item_dim, hidden_units=[32,16]):\n",
    "        super(AttentionUnit, self).__init__()\n",
    "        layers = []\n",
    "        in_dim = item_dim * 2\n",
    "        for hu in hidden_units:\n",
    "            layers.append(nn.Linear(in_dim, hu))\n",
    "            layers.append(nn.ReLU())\n",
    "            in_dim = hu\n",
    "        layers.append(nn.Linear(in_dim, 1))\n",
    "        self.mlp = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, hist, target):\n",
    "        L = hist.size(1)\n",
    "        target_exp = target.unsqueeze(1).repeat(1, L, 1)\n",
    "        concat = torch.cat([hist, target_exp], dim=2)\n",
    "        scores = self.mlp(concat).squeeze(-1)\n",
    "        att_weights = torch.softmax(scores, dim=1).unsqueeze(-1)\n",
    "        weighted = torch.sum(hist * att_weights, dim=1)\n",
    "        return weighted\n",
    "\n",
    "class DIN(nn.Module):\n",
    "    def __init__(self, user_dim, item_dim, hidden_units=[64,32], hist_len=5):\n",
    "        super(DIN, self).__init__()\n",
    "        self.attention = AttentionUnit(item_dim)\n",
    "        in_dim = user_dim + item_dim + item_dim\n",
    "        layers = []\n",
    "        cur_dim = in_dim\n",
    "        for hu in hidden_units:\n",
    "            layers.append(nn.Linear(cur_dim, hu))\n",
    "            layers.append(nn.ReLU())\n",
    "            cur_dim = hu\n",
    "        layers.append(nn.Linear(cur_dim, 1))\n",
    "        self.mlp = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, user_feat, item_feat, hist):\n",
    "        att_hist = self.attention(hist, item_feat)\n",
    "        concat = torch.cat([user_feat, item_feat, att_hist], dim=1)\n",
    "        logit = self.mlp(concat)\n",
    "        return torch.clamp(torch.sigmoid(logit), 1e-7, 1-1e-7).squeeze(-1)\n",
    "\n",
    "# 3.3 DeepFM 模型\n",
    "class DeepFM(nn.Module):\n",
    "    def __init__(self, input_dim, factor_dim=16, hidden_units=[64,32]):\n",
    "        super(DeepFM, self).__init__()\n",
    "        self.linear = nn.Linear(input_dim, 1)\n",
    "        self.V = nn.Parameter(torch.randn(input_dim, factor_dim))\n",
    "        layers = []\n",
    "        in_dim = input_dim\n",
    "        for hu in hidden_units:\n",
    "            layers.append(nn.Linear(in_dim, hu))\n",
    "            layers.append(nn.ReLU())\n",
    "            in_dim = hu\n",
    "        layers.append(nn.Linear(in_dim, 1))\n",
    "        self.deep = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        linear_part = self.linear(x)\n",
    "        xv = torch.matmul(x, self.V)\n",
    "        xv_square = xv * xv\n",
    "        x_square = x * x\n",
    "        v_square = self.V * self.V\n",
    "        x_square_v = torch.matmul(x_square, v_square)\n",
    "        fm_2nd = 0.5 * torch.sum(xv_square - x_square_v, dim=1, keepdim=True)\n",
    "        deep_out = self.deep(x)\n",
    "        logit = linear_part + fm_2nd + deep_out\n",
    "        return torch.clamp(torch.sigmoid(logit), 1e-7, 1-1e-7).squeeze(-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#########################################\n",
    "# 4. 训练与评估函数（对标签也做 clamp）\n",
    "#########################################\n",
    "\n",
    "def train_model(model, train_loader, val_loader, epochs=5, lr=1e-3, model_type='base'):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.BCELoss()\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        for batch in train_loader:\n",
    "            if model_type == 'din':\n",
    "                user_feat, item_feat, hist, label = batch\n",
    "                pred = model(user_feat, item_feat, hist)\n",
    "            else:\n",
    "                user_feat, item_feat, label = batch\n",
    "                if isinstance(model, DCN) or isinstance(model, DeepFM):\n",
    "                    x = torch.cat([user_feat, item_feat], dim=1)\n",
    "                    pred = model(x)\n",
    "                else:\n",
    "                    pred = model(user_feat, item_feat)\n",
    "            # 对 label 也 clamp 至 [0,1]\n",
    "            label = torch.clamp(label, 0, 1)\n",
    "            loss = criterion(pred, label)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        val_auc = evaluate_auc(model, val_loader, model_type)\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss/len(train_loader):.4f}, Val AUC: {val_auc:.4f}\")\n",
    "    return model\n",
    "\n",
    "def evaluate_auc(model, loader, model_type='base'):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    labels = []\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            if model_type == 'din':\n",
    "                user_feat, item_feat, hist, label = batch\n",
    "                out = model(user_feat, item_feat, hist)\n",
    "            else:\n",
    "                user_feat, item_feat, label = batch\n",
    "                if isinstance(model, DCN) or isinstance(model, DeepFM):\n",
    "                    x = torch.cat([user_feat, item_feat], dim=1)\n",
    "                    out = model(x)\n",
    "                else:\n",
    "                    out = model(user_feat, item_feat)\n",
    "            preds.append(out.cpu().numpy())\n",
    "            labels.append(label.cpu().numpy())\n",
    "    preds = np.concatenate(preds)\n",
    "    labels = np.concatenate(labels)\n",
    "    return roc_auc_score(labels, preds)\n",
    "\n",
    "def evaluate_ndcg(model, df, model_type='base', top_k=10):\n",
    "    model.eval()\n",
    "    user_groups = df.groupby('userId')\n",
    "    ndcg_list = []\n",
    "    with torch.no_grad():\n",
    "        for uid, group in user_groups:\n",
    "            items = group['movieId'].values\n",
    "            true_labels = group['label'].values\n",
    "            if np.sum(true_labels)==0 or np.sum(true_labels)==len(true_labels):\n",
    "                continue\n",
    "            scores = []\n",
    "            u_feat = torch.tensor(user_df[user_df['userId']==uid][user_feature_cols].values[0],\n",
    "                                  dtype=torch.float32).unsqueeze(0)\n",
    "            for i in items:\n",
    "                i_feat = torch.tensor(item_df[item_df['movieId']==i][item_feature_cols].values[0],\n",
    "                                      dtype=torch.float32).unsqueeze(0)\n",
    "                if model_type == 'din':\n",
    "                    hist = user_history.get(uid, [])\n",
    "                    max_hist = 5\n",
    "                    if len(hist) > max_hist:\n",
    "                        hist = hist[-max_hist:]\n",
    "                    else:\n",
    "                        while len(hist) < max_hist:\n",
    "                            hist.append(np.zeros_like(i_feat.numpy()[0]))\n",
    "                    hist = torch.tensor(np.array(hist), dtype=torch.float32).unsqueeze(0)\n",
    "                    score = model(u_feat, i_feat, hist)\n",
    "                else:\n",
    "                    x = torch.cat([u_feat, i_feat], dim=1)\n",
    "                    score = model(x)\n",
    "                scores.append(score.item())\n",
    "            order = np.argsort(scores)[::-1][:top_k]\n",
    "            dcg = 0.0\n",
    "            for rank, idx in enumerate(order, start=1):\n",
    "                if true_labels[idx] > 0:\n",
    "                    dcg += 1.0 / math.log2(rank + 1)\n",
    "            ideal_labels = sorted(true_labels, reverse=True)[:top_k]\n",
    "            idcg = 0.0\n",
    "            for rank, rel in enumerate(ideal_labels, start=1):\n",
    "                if rel > 0:\n",
    "                    idcg += 1.0 / math.log2(rank + 1)\n",
    "            if idcg > 0:\n",
    "                ndcg_list.append(dcg / idcg)\n",
    "    return np.mean(ndcg_list) if ndcg_list else 0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#########################################\n",
    "# 5. 模型训练与评估\n",
    "#########################################\n",
    "\n",
    "# 5.1 训练 DCN（基础数据集）\n",
    "print(\"\\nTraining DCN ...\")\n",
    "dcn_model = DCN(input_dim=input_dim, num_cross=2, deep_hidden=[64,32])\n",
    "dcn_model = train_model(dcn_model, train_loader_base, val_loader_base, epochs=5, lr=1e-3, model_type='base')\n",
    "auc_dcn = evaluate_auc(dcn_model, test_loader_base, model_type='base')\n",
    "ndcg_dcn = evaluate_ndcg(dcn_model, test_df, model_type='base', top_k=10)\n",
    "print(f\"DCN Test AUC: {auc_dcn:.4f}, NDCG@10: {ndcg_dcn:.4f}\")\n",
    "\n",
    "# 5.2 训练 DIN（DIN 数据集）\n",
    "print(\"\\nTraining DIN ...\")\n",
    "din_model = DIN(user_dim=user_dim, item_dim=item_dim, hidden_units=[64,32], hist_len=5)\n",
    "din_model = train_model(din_model, train_loader_din, val_loader_din, epochs=5, lr=1e-3, model_type='din')\n",
    "auc_din = evaluate_auc(din_model, test_loader_din, model_type='din')\n",
    "ndcg_din = evaluate_ndcg(din_model, test_df, model_type='din', top_k=10)\n",
    "print(f\"DIN Test AUC: {auc_din:.4f}, NDCG@10: {ndcg_din:.4f}\")\n",
    "\n",
    "# 5.3 训练 DeepFM（基础数据集）\n",
    "print(\"\\nTraining DeepFM ...\")\n",
    "deepfm_model = DeepFM(input_dim=input_dim, factor_dim=16, hidden_units=[64,32])\n",
    "deepfm_model = train_model(deepfm_model, train_loader_base, val_loader_base, epochs=5, lr=1e-3, model_type='base')\n",
    "auc_deepfm = evaluate_auc(deepfm_model, test_loader_base, model_type='base')\n",
    "ndcg_deepfm = evaluate_ndcg(deepfm_model, test_df, model_type='base', top_k=10)\n",
    "print(f\"DeepFM Test AUC: {auc_deepfm:.4f}, NDCG@10: {ndcg_deepfm:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
